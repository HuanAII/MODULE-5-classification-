{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuanAII/MODULE-5-classification-/blob/main/%5BHint%5D_A_ImgClf_MLP_ReLU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4sS0PFnr2Nu"
      },
      "source": [
        "## **0. Download dataset**\n",
        "**Note:** If you can't download using gdown due to limited number of downloads, please download it manually and upload it to your drive, then copy it from the drive to colab.\n",
        "```python\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "!cp /path/to/dataset/on/your/drive .\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVKQJrh6qhh9"
      },
      "outputs": [],
      "source": [
        "# https://drive.google.com/file/d/1GaTMURqIQTjtalbNVAyVgPIEis21A0r8/view?usp=drive_link\n",
        "!gdown --id 1GaTMURqIQTjtalbNVAyVgPIEis21A0r8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q './FER-2013.zip'"
      ],
      "metadata": {
        "id": "OdWLlB3MGIMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Import libraries**"
      ],
      "metadata": {
        "id": "PUWcf3M7iAk7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3bkvnjeX3Qw"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import Resize\n",
        "from torchvision.io import read_image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "random_state = 59\n",
        "np.random.seed(random_state)\n",
        "torch.manual_seed(random_state)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(random_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Get classes**"
      ],
      "metadata": {
        "id": "CGH7tyaeLflp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/train'\n",
        "test_dir = '/content/test'\n",
        "\n",
        "classes = os.listdir(train_dir)\n",
        "\n",
        "label2idx = {cls:idx for idx, cls in enumerate(classes)}\n",
        "idx2label = {idx:cls  for cls, idx in label2idx.items()}"
      ],
      "metadata": {
        "id": "rEdcNLkRLhW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Create PyTorch DataLoader**"
      ],
      "metadata": {
        "id": "NrZ520zomN8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_path = '/content/train/angry/Training_10118481.jpg'\n",
        "img = cv2.imread(test_img_path)\n",
        "img_height, img_width = (128, 128)\n",
        "print(f'Image height: {img_height}')\n",
        "print(f'Image width: {img_width}')"
      ],
      "metadata": {
        "id": "wtJk3nx3HJAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il-wRorLdmTV"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, norm, label2idx,\n",
        "                 split='train', train_ratio=0.8):\n",
        "        pass\n",
        "\n",
        "    def read_img_files(self):\n",
        "\n",
        "        return None\n",
        "\n",
        "    def __len__(self):\n",
        "        return None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Build MLP network**"
      ],
      "metadata": {
        "id": "qT1Fm6YgoCRZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Co98aXfydtz0"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dims, hidden_dims, output_dims):\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJzhhPUn4zy8"
      },
      "source": [
        "## **5. Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kY1rB1usfEUc"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(y_hat, y_true):\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4krCCYspfI4W"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    train_target = []\n",
        "    train_predict = []\n",
        "    model.train()\n",
        "    for X_samples, y_samples in train_loader:\n",
        "        X_samples = X_samples.to(device)\n",
        "        y_samples = y_samples.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_samples)\n",
        "        loss = criterion(outputs, y_samples)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        train_predict.append(outputs.detach().cpu())\n",
        "        train_target.append(y_samples.cpu())\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    train_predict = torch.cat(train_predict)\n",
        "    train_target = torch.cat(train_target)\n",
        "    train_acc = compute_accuracy(train_predict, train_target)\n",
        "    train_accs.append(train_acc)\n",
        "\n",
        "    val_loss = 0.0\n",
        "    val_target = []\n",
        "    val_predict = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X_samples, y_samples in val_loader:\n",
        "            X_samples = X_samples.to(device)\n",
        "            y_samples = y_samples.to(device)\n",
        "            outputs = model(X_samples)\n",
        "            val_loss += criterion(outputs, y_samples).item()\n",
        "\n",
        "            val_predict.append(outputs.cpu())\n",
        "            val_target.append(y_samples.cpu())\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    val_predict = torch.cat(val_predict)\n",
        "    val_target = torch.cat(val_target)\n",
        "    val_acc = compute_accuracy(val_predict, val_target)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    print(f'\\nEPOCH {epoch + 1}:\\tTraining loss: {train_loss:.3f}\\tValidation loss: {val_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBoqX7xMfNxK"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
        "ax[0, 0].plot(train_losses, color='green')\n",
        "ax[0, 0].set(xlabel='Epoch', ylabel='Loss')\n",
        "ax[0, 0].set_title('Training Loss')\n",
        "\n",
        "ax[0, 1].plot(val_losses, color='orange')\n",
        "ax[0, 1].set(xlabel='Epoch', ylabel='Loss')\n",
        "ax[0, 1].set_title('Validation Loss')\n",
        "\n",
        "ax[1, 0].plot(train_accs, color='green')\n",
        "ax[1, 0].set(xlabel='Epoch', ylabel='Accuracy')\n",
        "ax[1, 0].set_title('Training Accuracy')\n",
        "\n",
        "ax[1, 1].plot(val_accs, color='orange')\n",
        "ax[1, 1].set(xlabel='Epoch', ylabel='Accuracy')\n",
        "ax[1, 1].set_title('Validation Accuracy')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. Evaluation**"
      ],
      "metadata": {
        "id": "Z8sKnabn7Hf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_target = []\n",
        "val_predict = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X_samples, y_samples in val_loader:\n",
        "        X_samples = X_samples.to(device)\n",
        "        y_samples = y_samples.to(device)\n",
        "        outputs = model(X_samples)\n",
        "\n",
        "        val_predict.append(outputs.cpu())\n",
        "        val_target.append(y_samples.cpu())\n",
        "\n",
        "    val_predict = torch.cat(val_predict)\n",
        "    val_target = torch.cat(val_target)\n",
        "    val_acc = compute_accuracy(val_predict, val_target)\n",
        "\n",
        "    print('Evaluation on val set:')\n",
        "    print(f'Accuracy: {val_acc}')"
      ],
      "metadata": {
        "id": "D4p8aiMw7JNI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}